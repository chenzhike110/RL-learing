####  机器人技能学习  robot learning

- 机器人行为学习是机器人领域的研究热点

- #### robot learning 的核心问题：让机器人自己学会各种决策控制任务

- #### 技能定义	action序列

  - 按技能复杂性划分
    - 单阶段
    - **复合技能 sequential decision**
  - 按action类型划分
    - 决策问题（离散）
    - **轨迹、规划（连续空间）**

- #### 机器人多步决策复合技能学习现状

  - 传统控制算法
    - **Programming based**
    - 对控制对象进行建模然后人为定义控制律进行规划，通过**分别解决每个单步决策过程**求解多步决策
      - 大量计算实时性差，建模误差对环境适应性较差
  - 传统控制+深度学习
    - GPS Guided Policy Search (2013 Sergey Levine)
      - 利用传统控制算法分类分步解决各个阶段的决策然后辅助训练深度学习模型实现端到端
      - 需要知道整个系统的精确模型
      - 需要大量样本数据

  - 纯学习的方法
    - 模仿学习多步决策
      - **teaching reproduction**
      - 行为克隆（Nvidia 无人驾驶）
        - 将状态与动作配对，进行监督学习逼近专家动作
        - 实现简单，不需要仿真环境，**可以直接解决多步决策**
        - 需要大量数据cover整个状态空间
        - 鲁棒性差，实际场景效果不佳，缺乏对行为内涵的认识
      - 逆强化学习（OpenAI 2016 机械臂搭积木）
        - 利用神经网络与专家样本抽象出一个Reward函数，然后再进行强化学习
        - 难以再复杂场景中Work，**只能针对单阶段决策**
      - GAN + VAE encoder (Deep Mind 仿人机器人)
        - 通过encoder提取专家数据的图像信息，可以模仿多种行为
        - 多种行为的本质仍然是相似的
      - **模仿学习需要质量较高的专家数据，在高动态环境中难以获得**
    - 强化学习多步决策
      - 利用强化学习可以简单高效地解决单阶段决策任务
        - 强化学习将策略抽象为黑盒进行优化，失去了skill本身的结构，多步决策难以直接训练。
      - Multi-Task 强化学习
        - 主要思路是寻找task之间的相似性，训练得到一个能同时完成多个任务的agent
        - 将分步决策分为多个subtask，训练得到可以解决多个决策任务的一个Agent
          - 结构简单
          - **如果多步决策中每个subtask之间缺乏相似性，就难以训练得到模型**
      - 利用分类神经网络+强化学习实现多步决策（2019 Science        Robot skill acquisition in assembly process using deep reinforcement learning    机械臂分拣任务）
        - **利用监督学习训练分类器**，调用利用强化学习训练的agent分步解决
        - 分类器仍需要人工标注监督学习

- #### Our Work

  - 将多步决策问题划分为单步决策问题，利用强化学习分别解决，再利用强化学习将两个action序列进行组合从而直接单纯利用强化学习解决多步决策问题，为机器人多步决策技能提供了一种更加方便高效的方法

  - 选取RoboCup中移动机器人的追球射门决策过程

  - 基于RoboCup实验平台分别训练到点吸球和射门技能

  - 利用强化学习进行组合，实现完整的追球射门技能，验证了方法的可行性

    

